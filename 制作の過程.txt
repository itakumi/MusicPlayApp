最初ピッチシフトとタイムストレッチの機能を備えたプレイヤーを作りたいと思ったところから始まりました。
まずは原理から知ってみたいと思い、ピッチシフトとタイムストレッチをする箇所において高性能オーディオライブラリは使わずにnumpyやリサンプリングの関数のみで実装しました。(それが「愚直アルゴリズム」ディレクトリのものです)
愚直アルゴリズムはhttp://ackiesound.ifdef.jp/tech/timestretch.htmlの記事を参考に波に対して時間方向にブロック単位で切り出しを行い(これによってタイムストレッチが行えます)、それをリサンプリング(ブロック切り出しと併用することでピッチシフトが実現できます)することでピッチシフトとタイムストレッチを行っています。
しかし、このままだとブロックの境界部分が離散的になるためプツプツといった雑音が聞こえてしまいます。
そのため、前のブロックの最後の部分と後のブロックの最初の部分をcosカーブ等を用いて重ね合わせるクロスフェードという技術を使いました。
これによってプツプツ音は回避できますが、声が震えてしまう時があります。

次に行ったのがFlanagan & Golden (1966)という方によって発見されたフェーズボコーダというアルゴリズムです。
これは
1.曲データに対して短時間フーリエ変換(STFT)というブロック単位に分けてフーリエ変換する技術を用いて時間領域のデータを周波数領域に変換し、
2.周波数領域のデータに対してリサンプリングを行い(これによってタイムストレッチが実現できます)
3.逆STFTで時間領域のデータに戻す
といったやり方になっております。
実際にこれをnumpyで実装してみたものが「愚直アルゴリズム&stft」ディレクトリにあります。
ただ、フェーズボコーダもhttps://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A7%E3%83%BC%E3%82%BA%E3%83%9C%E3%82%B3%E3%83%BC%E3%83%80#CITEREFFlanaganGolden1966に載っているようにノイズが発生することが想定されています。
このノイズに関して今の段階だと愚直アルゴリズムの方が音質が良いと感じました。

ここでさらに音質を上げるために高性能オーディオライブラリ「librosa」を使って実装してみました。(それが「WithLibrosa」ディレクトリにあるものです。)
ただLibrosaのピッチシフトやタイムストレッチもstftを使っているので本来は曲データを一度に全て持ってきて適用する必要があるのですが、それだと音楽を再生中に音程を変換できないのでchunkを比較的長めに取り、約3秒のデータを一度に取り込むことによって対応しました。
しかし、このままだと音程変換ボタンを押したときに最高で3秒応答に時間がかかってしまいます。そのため、chunkとbufferの値を分けることでボタンを押したときに少しでも速くプログラムが応答するようにしています。

当時のプログラムには
1.マルチスレッドにおいて意図していないような並列処理が行われていた
2.プレイリスト選択画面が再生中に応答なしになってしまう
3.出力デバイスが選択できない
4.全て文字のボタンなのでデザインがあまりよくない
5.今どの再生モードなのかがわかりづらい
といった問題が多くあったのでそれらを全て一つずつ改善していきました。

プレイヤーを作ってみた感想として
愚直アルゴリズム、WithLibrosaが良いと感じました。
それぞれのメリット、デメリットとして
愚直アルゴリズム
メリット→応答時間が速い
デメリット→若干声が震えている

WithLibrosa
メリット→音質が良い
デメリット→応答時間が若干長い

となりました。

この2つのアルゴリズムを聞き分けられるようにしたプログラムがMusicPlayAppディレクトリにあるものです。
さらにこれまでのものと比べて以下の改良を行いました。
・ピッチシフトとタイムストレッチを別スレッドで行うことで応答時間を短縮
